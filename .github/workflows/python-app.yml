name: åœ¨çº¿ä¸‹è½½å°è¯´2

on:
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘å·¥ä½œæµ
    inputs:
      novel_url:
        description: 'å°è¯´é˜…è¯»é¡µURL (ä¸ƒçŒ«: https://www.qimao.com/reader/index/1673946/)'
        required: true
        type: string
      threads:
        description: 'ä¸‹è½½çº¿ç¨‹æ•° (1-5ï¼Œå»ºè®®â‰¤3é¿å…åçˆ¬)'
        required: true
        default: '2'
      format:
        description: 'è¾“å‡ºæ ¼å¼'
        required: true
        type: choice
        options:
          - txt
          - epub
        default: 'txt'

# æ·»åŠ å¿…è¦çš„æƒé™
permissions:
  contents: read
  actions: write

jobs:
  download-novel:
    runs-on: ubuntu-latest
    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v3
        
      - name: è®¾ç½®Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          
      - name: å®‰è£…ä¾èµ–
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml ebooklib  # ä¾èµ–åº“
          
      - name: ç¼–å†™å°è¯´çˆ¬å–è„šæœ¬
        run: |
          cat > novel_spider.py << 'EOF'
          import re
          import sys
          import time
          import random
          from concurrent.futures import ThreadPoolExecutor, as_completed
          import requests
          from bs4 import BeautifulSoup
          from ebooklib import epub

          # é…ç½®é¡¹
          HEADERS = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          }
          DELAY = (1, 3)  # è¯·æ±‚å»¶æ—¶èŒƒå›´(ç§’)

          def extract_novel_id(novel_url):
              """ä»URLä¸­æå–å°è¯´ID"""
              match = re.search(r"/reader/index/(\d+)/", novel_url)
              if not match:
                  raise ValueError("æ— æ•ˆçš„ä¸ƒçŒ«å°è¯´URL")
              return match.group(1)

          def get_chapter_list(novel_id):
              """è·å–å°è¯´ç« èŠ‚åˆ—è¡¨ä¸æ ‡é¢˜"""
              chapter_url = f"https://www.qimao.com/reader/index/{novel_id}/"
              response = requests.get(chapter_url, headers=HEADERS, timeout=10)
              response.raise_for_status()
              soup = BeautifulSoup(response.text, "lxml")
              
              # æå–å°è¯´æ ‡é¢˜
              novel_title = soup.find("h1", class_="book-title")
              novel_title = novel_title.text.strip() if novel_title else "æœªçŸ¥å°è¯´"
              
              # æå–ç« èŠ‚åˆ—è¡¨ (ä¸ƒçŒ«ç« èŠ‚åˆ—è¡¨åœ¨ç« èŠ‚é€‰æ‹©å™¨ä¸­)
              chapter_list = []
              chapter_items = soup.select("ul.chapter-list li a")
              for item in chapter_items:
                  chapter_title = item.text.strip()
                  chapter_href = item.get("href")
                  if not chapter_href.startswith("http"):
                      chapter_href = f"https://www.qimao.com{chapter_href}"
                  chapter_list.append({"title": chapter_title, "url": chapter_href})
              return novel_title, chapter_list[:482]  # é™åˆ¶482ç« 

          def get_chapter_content(chapter_info):
              """è·å–å•ç« å†…å®¹"""
              title = chapter_info["title"]
              url = chapter_info["url"]
              try:
                  time.sleep(random.uniform(*DELAY))  # éšæœºå»¶æ—¶
                  response = requests.get(url, headers=HEADERS, timeout=10)
                  response.raise_for_status()
                  soup = BeautifulSoup(response.text, "lxml")
                  # æå–æ­£æ–‡å†…å®¹ (ä¸ƒçŒ«æ­£æ–‡åœ¨contentç±»æ ‡ç­¾)
                  content_div = soup.find("div", class_="content")
                  if not content_div:
                      return title, "ã€ç« èŠ‚å†…å®¹è·å–å¤±è´¥ã€‘"
                  # æ¸…ç†å¹¿å‘Šä¸æ— å…³æ ‡ç­¾
                  for ad in content_div.select("script, style, .ad-wrap"):
                      ad.decompose()
                  content = content_div.text.strip().replace("\u3000\u3000", "\n  ")
                  return title, content
              except Exception as e:
                  return title, f"ã€ç« èŠ‚è·å–å¼‚å¸¸: {str(e)}ã€‘"

          def save_to_txt(novel_title, chapters, save_path):
              """ä¿å­˜ä¸ºTXTæ–‡ä»¶"""
              txt_path = f"{save_path}/{novel_title}.txt"
              with open(txt_path, "w", encoding="utf-8") as f:
                  f.write(f"{novel_title}\n\n")
                  for title, content in chapters:
                      f.write(f"==== {title} ====\n")
                      f.write(content + "\n\n")
              return txt_path

          def save_to_epub(novel_title, chapters, save_path):
              """ä¿å­˜ä¸ºEPUBæ–‡ä»¶"""
              epub_path = f"{save_path}/{novel_title}.epub"
              book = epub.EpubBook()
              book.set_title(novel_title)
              book.set_language("zh")
              
              # æ·»åŠ ç« èŠ‚
              epub_chapters = []
              for title, content in chapters:
                  c = epub.EpubHtml(title=title, file_name=f"chap_{title.replace('/', '_')}.xhtml", lang="zh")
                  c.content = f"<h1>{title}</h1><p>{content.replace('\n', '</p><p>')}</p>"
                  book.add_item(c)
                  epub_chapters.append(c)
              
              book.toc = tuple(epub_chapters)
              book.add_item(epub.EpubNcx())
              book.add_item(epub.EpubNav())
              book.spine = ["nav"] + epub_chapters
              epub.write_epub(epub_path, book, {})
              return epub_path

          def main():
              if len(sys.argv) != 4:
                  print("ç”¨æ³•: python novel_spider.py <novel_url> <output_format> <threads>")
                  sys.exit(1)
              
              novel_url = sys.argv[1]
              output_format = sys.argv[2].lower()
              threads = int(sys.argv[3])
              save_path = "novel_output"
              os.makedirs(save_path, exist_ok=True)
              
              try:
                  novel_id = extract_novel_id(novel_url)
                  print(f"æå–å°è¯´ID: {novel_id}")
                  novel_title, chapter_list = get_chapter_list(novel_id)
                  print(f"è·å–åˆ° {len(chapter_list)} ç« ï¼Œå¼€å§‹ä¸‹è½½...")
                  
                  # å¤šçº¿ç¨‹ä¸‹è½½ç« èŠ‚
                  chapters_content = []
                  with ThreadPoolExecutor(max_workers=threads) as executor:
                      futures = [executor.submit(get_chapter_content, chap) for chap in chapter_list]
                      for future in as_completed(futures):
                          chapters_content.append(future.result())
                  # æŒ‰åŸç« èŠ‚é¡ºåºæ’åº
                  chapters_content = sorted(chapters_content, key=lambda x: chapter_list.index(next(c for c in chapter_list if c['title'] == x[0])))
                  
                  # ä¿å­˜æ–‡ä»¶
                  if output_format == "txt":
                      output_file = save_to_txt(novel_title, chapters_content, save_path)
                  elif output_format == "epub":
                      output_file = save_to_epub(novel_title, chapters_content, save_path)
                  else:
                      raise ValueError("ä¸æ”¯æŒçš„æ ¼å¼")
                  print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_file}")
              except Exception as e:
                  print(f"é”™è¯¯: {str(e)}")
                  sys.exit(1)

          if __name__ == "__main__":
              import os
              main()
          EOF
          
      - name: è¿è¡Œçˆ¬å–è„šæœ¬
        run: |
          mkdir -p novel_output
          python novel_spider.py "${{ github.event.inputs.novel_url }}" "${{ github.event.inputs.format }}" "${{ github.event.inputs.threads }}"
          
      - name: å‹ç¼©ç»“æœæ–‡ä»¶
        run: |
          cd novel_output && zip -r ../novel_result.zip *
          
      - name: ä¸Šä¼ äº§ç‰©
        uses: actions/upload-artifact@v4
        with:
          name: novel-result-${{ github.event.inputs.format }}
          path: novel_result.zip
          retention-days: 7
          
      - name: å®Œæˆæç¤º
        run: |
          echo "ğŸ‰ å°è¯´ä¸‹è½½å®Œæˆï¼äº§ç‰©å·²ä¸Šä¼ è‡³Action Artifactsï¼Œæœ‰æ•ˆæœŸ7å¤©ã€‚"
